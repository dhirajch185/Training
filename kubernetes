kubectl get pods
kubectl get pods -o wide
kubectl describe pod <podname>
kubectl create -f <podcreation.yaml filename> ---------- Delcarative Way
kubectl run mynginx_podname --image=nginx_dockerHubImageName ---- imperative way
kubectl describe pod <pod_name> | grep -c "Containers:"  ---------> to find the number of containers used in the pod
kubectl create -f .\rc-definition.yaml (Create replication Controller)
kubectl delete rc myapp-rc ----- Delete replication controller
kubectl get replicaset
kubectl replace -f replicaset-definition.yaml ( will replace the existing replicaset with any new changes) --- Declarative way
kubectl scale --replicas=6 -f replicaset-definition.yaml -- Imperative way
kubectl scale --replicas=6 replicaset myapp-replicaset --- Imperative way with type & name format
kubectl edit replicaset myapp-replicaset ------------ Risky.. Imperative way to make changes to the replicaset. Note: Careful.. Saving the edited file will immediately apply the changes.
kubectl delete replicaset myapp-replicaset -- Delete replicaset
kubectl create -f deployment-definition.yaml
kubectl get deployments
kubectl get all  ----------------- Shows all the resources created
kubectl get pods,svc ----------------- Shows just pods and services created
kubectl rollout status deployment/myapp-deployment
kubectl apply -f deployment-definition.yaml  ----------- Make changes to the deployment yaml (like image version) and upgrade
kubectl set image deployment/myapp-deployment \ nginx-container=nginx:1.9.1 ------- upgrading imperatively using container name (only for toubelshooting)

kubectl rollout status deployment.apps/myapp-deployment
kubectl rollout history deployment/myapp-deployment
kubectl rollout undo deployment/myapp-deployment

kubectl create -f .\service-definition.yaml
kubectl get services
minikube service myapp-service --url -------------------- to get the url of service running on minikube node

kubectl delete pods --all -n default ------- Deltes all the pods running on the namespace by the name 'default'


---------------------namespace ---------------------

kubectl config set-context $(kubectl config current-context) --namespace=dev  --> Permanently switch to a namespace so no namespace mentioned everytime
kubectl get pods --all-namespaces -----> get pods form all namespaces
------------- Troubleshooting -----------------
After fixing the image name, you can re-deploy the changes using below command
kubectl apply -f podCreate.yaml
         or
kubectl edit pod <podName>
Then check the pod details, you should see the STATUS as running

---------------- Terminologies ---------------
replication controller - create multiple pods or nodes to load balance. (older technology and obsolete)
Replica set - new way of implementation (apiversion : apps/v1, selector mandatory)
Poda - apiVersion is v1
Rolling upgrade.
cillium/flannel - used for internal routing, ip address allocation between nodes and pods in a cluster
NodePort (range 30000 to 32767)
ClusterIP
LoadBalancer


--------------------- Binding for Manual scheduling ---------------
create a 'Binding' object (yaml file) to assign a node name to a existing pod and send a post request to the pod's binding api.
Thus mimicking what the actual scheduler does.

---------------- scenarios -------------
kubectl get pods --selector app=App1     -> filters all the pods with the label selector app=App1

kubectl taint nodes node-name key:value:taint-effect ----> to taint (label) the nodes so pods which do not tolerate (match the labels) the taint will not be placed in the node with the taint value.

Pods which do not tolerate the taint will have 3 response status ---> NoSchedule (pods will not be scheduled on the nodes), PreferNoSchedule (system will try to place the pod on the node but 'no gurantee'), NoExecute (New pods will not be scheduled and any existing pods which do not tolerate the taint will be evicted as well from the node) 

example: kubectl taint nodes node1 app=blue:NoSchedule

Tolerations are added to the pods with tolerations added to spec of the pod yaml defition.
spec:
  tolerations:
    - key: "app"
      operator: "Equal"
      value: "blue"
      effect: "NoSchedule"
*********Note: taint and toleration doesnt mean the tolerated pod always ends up in a tainted node. it can be distributed to untainted node as well. This is just to restrict the specific nodes to have only certain type of pods. To ensure required pods to end up to required nodes, we use a different concept called 'NodeAffinity'



